{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to TapeAgents for Bedrock Claude LLM!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**TapeAgents** is a framework that leverages a structured, replayable log (**Tape**) of the agent session to facilitate all stages of the LLM Agent development lifecycle. In TapeAgents, the agent reasons by processing the tape and the LLM output to produce new thoughts, actions, control flow steps and append them to the tape. The environment then reacts to the agent’s actions by likewise appending observation steps to the tape.\n",
    "\n",
    "In this tutorial, you will learn:\n",
    "- how to create TapeAgents using the low-level API\n",
    "- run and resume TapeAgents\n",
    "- have one TapeAgent reuse another TapeAgent's tape as training data\n",
    "\n",
    "In upcoming versions of this tutorial, you will also learn: \n",
    "- how to make a team TapeAgent with subagents\n",
    "- how to build TapeAgents using available high-level APIs\n",
    "- how to build a TapeAgent that streams partial steps\n",
    "\n",
    "Other tutorials and examples will cover:\n",
    "- code execution and browser use\n",
    "- finetuning\n",
    "- the TapeAgents apps (Studio and Browser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "We're assuming that you already installed the project through the `make setup` or the jupyter notebook is running in the context of the project. If not, please refer to the [README](README.md) for more detailed instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T13:10:23.372986Z",
     "iopub.status.busy": "2025-06-10T13:10:23.372480Z",
     "iopub.status.idle": "2025-06-10T13:10:23.385457Z",
     "shell.execute_reply": "2025-06-10T13:10:23.384604Z"
    }
   },
   "outputs": [],
   "source": [
    "# Now set the BEDROCK_CLAUDE_API_KEY environment variable to your API key.\n",
    "\n",
    "import os\n",
    "\n",
    "if \"BEDROCK_CLAUDE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"BEDROCK_CLAUDE_API_KEY\"] = \"<your-api-key>\"\n",
    "    # os.environ[\"BEDROCK_CLAUDE_ORGANIZATION\"] = \"\" # optional\n",
    "today = \"2025-06-10\"  # fixed date for reproducible tests\n",
    "\n",
    "\n",
    "# If you prefer to skip the Bedrock Claude setup and not make any LLM calls, you can use ones from the cache.\n",
    "# it will work instead of the real LLM fine as long as the prompts are not changed.\n",
    "# Uncomment the following lines to use the cache:\n",
    "#\n",
    "# from tapeagents import llms\n",
    "# import os\n",
    "# llm_cache_path = \"tests/res/intro_notebook/tapedata.sqlite\"\n",
    "# if not os.path.exists(llm_cache_path):\n",
    "#     llm_cache_path = f\"../{llm_cache_path}\"\n",
    "# assert os.path.exists(llm_cache_path)\n",
    "# llms._REPLAY_SQLITE = llm_cache_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Your first TapeAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will build the simplest possible \"hello world\" agent. We will then go through all the new concepts that you need to know to understand the code. This section is quite long, but with the solid foundation you acquire here other TapeAgent tutorials will be easy to process.\n",
    "\n",
    "Without further ado, here's the code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T13:10:23.390548Z",
     "iopub.status.busy": "2025-06-10T13:10:23.390186Z",
     "iopub.status.idle": "2025-06-10T13:10:28.060765Z",
     "shell.execute_reply": "2025-06-10T13:10:28.060061Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oleh.shliazhko/TapeAgents/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final tape: {\n",
      "  \"metadata\": {\n",
      "    \"id\": \"d0d10c89-65b7-4a3c-993b-abc63e61d9b7\",\n",
      "    \"parent_id\": \"8ebf62cb-64ed-46d6-b407-df9c80283be9\",\n",
      "    \"author\": \"Agent\",\n",
      "    \"author_tape_id\": null,\n",
      "    \"n_added_steps\": 2,\n",
      "    \"error\": null,\n",
      "    \"result\": {}\n",
      "  },\n",
      "  \"context\": null,\n",
      "  \"steps\": [\n",
      "    {\n",
      "      \"metadata\": {\n",
      "        \"id\": \"421b7b7c-cc61-45e7-8b77-b1fc894dfe2c\",\n",
      "        \"prompt_id\": \"\",\n",
      "        \"node\": \"\",\n",
      "        \"agent\": \"\",\n",
      "        \"llm\": \"\",\n",
      "        \"other\": {}\n",
      "      },\n",
      "      \"kind\": \"user\",\n",
      "      \"content\": \"Tell me about Vulcan in 3 sentences\"\n",
      "    },\n",
      "    {\n",
      "      \"metadata\": {\n",
      "        \"id\": \"dab90836-249a-4e5b-b0bf-d565de8529c0\",\n",
      "        \"prompt_id\": \"e85f2f34-57eb-4514-a842-c2f12d673726\",\n",
      "        \"node\": \"main\",\n",
      "        \"agent\": \"Agent\",\n",
      "        \"llm\": \"default\",\n",
      "        \"other\": {}\n",
      "      },\n",
      "      \"kind\": \"assistant\",\n",
      "      \"content\": \"Vulcan is a fictional planet in the \\\"Star Trek\\\" universe, known as the home of the Vulcan species, including the iconic character Spock. The Vulcans are characterized by their logical minds, emotional control, and advanced technology, having a rich cultural history that emphasizes peace and science. The planet itself features a harsh landscape with mountainous regions and arid environments, and it plays a crucial role in the wider narrative of the \\\"Star Trek\\\" saga.\"\n",
      "    },\n",
      "    {\n",
      "      \"metadata\": {\n",
      "        \"id\": \"1e580704-3106-49f1-b762-10b747a89c4a\",\n",
      "        \"prompt_id\": \"e85f2f34-57eb-4514-a842-c2f12d673726\",\n",
      "        \"node\": \"main\",\n",
      "        \"agent\": \"Agent\",\n",
      "        \"llm\": \"default\",\n",
      "        \"other\": {}\n",
      "      },\n",
      "      \"kind\": \"set_next_node\",\n",
      "      \"next_node\": \"main\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from tapeagents.agent import Agent, Node\n",
    "from tapeagents.core import Prompt, SetNextNode\n",
    "from tapeagents.dialog_tape import AssistantStep, DialogTape, UserStep\n",
    "from tapeagents.llms import LiteLLM, LLMStream\n",
    "from tapeagents.prompting import tape_to_messages\n",
    "\n",
    "llm = LiteLLM(model_name=\"bedrock-claude-mini\")\n",
    "\n",
    "\n",
    "class MainNode(Node):\n",
    "    name: str = \"main\"\n",
    "\n",
    "    def make_prompt(self, agent: Agent, tape: DialogTape) -> Prompt:\n",
    "        # Render the whole tape into the prompt, each step is converted to message\n",
    "        return Prompt(messages=tape_to_messages(tape))\n",
    "\n",
    "    def generate_steps(self, agent: Agent, tape: DialogTape, llm_stream: LLMStream):\n",
    "        yield AssistantStep(content=llm_stream.get_text())  # Generate new step from the LLM output stream.\n",
    "        yield SetNextNode(next_node=\"main\")  # Which node to execute next, more on that later\n",
    "\n",
    "\n",
    "agent = Agent[DialogTape].create(llm, nodes=[MainNode()])\n",
    "start_tape = DialogTape(steps=[UserStep(content=\"Tell me about Vulcan in 3 sentences\")])\n",
    "final_tape = agent.run(start_tape).get_final_tape()  # agent will start executing the first node\n",
    "print(f\"Final tape: {final_tape.model_dump_json(indent=2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's learn about tapes, steps, prompts, llm streams, nodes and agents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tape\n",
    "\n",
    "The fundamental concept of the TapeAgents is the `Tape`, a comprehensive semantic level log of the agent's session. A `Tape` contains a context and a sequence of `Step` objects. As you can see, a TapeAgent runs by adding steps (such as `UserStep` or `AssistantStep`) to the _tape_. This example uses the `DialogTape` tape, which is a basic tape for user-assistant conversations. Let's see what are the possible steps in a `DialogTape`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T13:10:28.063008Z",
     "iopub.status.busy": "2025-06-10T13:10:28.062749Z",
     "iopub.status.idle": "2025-06-10T13:10:28.078690Z",
     "shell.execute_reply": "2025-06-10T13:10:28.078394Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tapeagents.core.Tape[Union[DialogContext, NoneType], Union[UserStep, ToolResult, SystemStep, AssistantThought, SetNextNode, Pass, Call, Respond, FinalStep, AssistantStep, ToolCalls]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We use Python generics to instantiate many different Tape types by\n",
    "# specifying different Context and Step types. In the output of this cell,\n",
    "# look at Union[UserStep, AssistantStep, ...]\n",
    "# for the list of possible step types in the DialogTape.\n",
    "DialogTape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of these steps should be familiar to you. `UserStep`, `AssistantStep`, `SystemStep` and `ToolResult` correspond to `role=user`, `role=assistant`, `role=system` and `role=tool` LLM API messages respectively. `ToolCalls` and `AssistantThought` correspond to assistant messages where the LLM requests a tool call or produces an intermediate thought that is not meant to be shown to the user. `SetNextNode` and `Pass` are TapeAgent's internal step to control which node it should run at the next iteration (more on this below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt format; LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the industry-standard \"chat.completions\" prompt format in TapeAgents: a list of user/assistant/system/tool messages plus tool schemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T13:10:28.080106Z",
     "iopub.status.busy": "2025-06-10T13:10:28.079993Z",
     "iopub.status.idle": "2025-06-10T13:10:28.082494Z",
     "shell.execute_reply": "2025-06-10T13:10:28.082044Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': FieldInfo(annotation=str, required=False, default_factory=<lambda>),\n",
       " 'tools': FieldInfo(annotation=Union[list[dict], NoneType], required=False, default=None),\n",
       " 'messages': FieldInfo(annotation=list[dict], required=False, default_factory=list),\n",
       " 'token_ids': FieldInfo(annotation=list[int], required=False, default_factory=list)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Almost all classes in TapeAgents are Pydantic base models.\n",
    "# This allows easy validation, serialization and instrospection. For example,\n",
    "# here we are able to list all the fields in the Prompt model.\n",
    "Prompt.model_fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LLMs in TapeAgent take `Prompt` and return an `LLMStream` object. The `LLMStream` object can be used both to fast-forward to the complete response text and to stream partial outputs step by step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T13:10:28.084376Z",
     "iopub.status.busy": "2025-06-10T13:10:28.084246Z",
     "iopub.status.idle": "2025-06-10T13:10:33.727263Z",
     "shell.execute_reply": "2025-06-10T13:10:33.726750Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Here’s a simple example of a \""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, World!\" program in Java:\n",
      "\n",
      "```java\n",
      "public class Hello"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World {\n",
      "    public static void main(String[] args) {\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        System.out.println(\"Hello, World!\");\n",
      "    }\n",
      "}\n",
      "```\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To run this program:\n",
      "\n",
      "1. Save the code in a file named `Hello"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World.java`.\n",
      "2. Open your command line or terminal.\n",
      "3. Navigate to"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the directory where the file is saved.\n",
      "4."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Compile the code using the command: `javac HelloWorld.java`\n",
      "5."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Run the compiled program using the command: `java HelloWorld`\n",
      "\n",
      "You should see"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the output:\n",
      "\n",
      "```\n",
      "Hello, World!\n",
      "```None\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Here is a simple \"Hello, World!\" program written in C:\n",
      "\n",
      "```c\n",
      "#include <stdio.h>\n",
      "\n",
      "int main() {\n",
      "    printf(\"Hello, World!\\n\");\n",
      "    return 0;\n",
      "}\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "- `#include <stdio.h>`: This line includes the standard input-output library, which is necessary for using the `printf` function.\n",
      "- `int main()`: This defines the main function, which is the entry point of the program.\n",
      "- `printf(\"Hello, World!\\n\");`: This line prints \"Hello, World!\" followed by a newline character to the standard output.\n",
      "- `return 0;`: This indicates that the program has finished executing successfully.\n",
      "\n",
      "To compile and run this code:\n",
      "1. Save it in a file named `hello.c`.\n",
      "2. Open a terminal and navigate to the directory where you saved the file.\n",
      "3. Compile the program using a C compiler, like `gcc`:\n",
      "   ```\n",
      "   gcc hello.c -o hello\n",
      "   ```\n",
      "4. Run the compiled program:\n",
      "   ```\n",
      "   ./hello\n",
      "   ```\n",
      "\n",
      "You should see `Hello, World!` printed on the screen.\n"
     ]
    }
   ],
   "source": [
    "llm_stream = LiteLLM(model_name=\"bedrock-claude-mini-2025-06-10\", stream=True)\n",
    "\n",
    "# Streaming\n",
    "prompt = Prompt(messages=[{\"role\": \"user\", \"content\": \"Write hello world in Java\"}])\n",
    "for event in llm_stream:\n",
    "    print(event.get_text(), end=\"\")"
   ]
  }
 ]
}